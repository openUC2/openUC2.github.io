"use strict";(self.webpackChunkuc_2_docs=self.webpackChunkuc_2_docs||[]).push([[2990],{3905:(e,n,t)=>{t.d(n,{Zo:()=>m,kt:()=>u});var i=t(67294);function a(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function r(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);n&&(i=i.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,i)}return t}function o(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?r(Object(t),!0).forEach((function(n){a(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):r(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function s(e,n){if(null==e)return{};var t,i,a=function(e,n){if(null==e)return{};var t,i,a={},r=Object.keys(e);for(i=0;i<r.length;i++)t=r[i],n.indexOf(t)>=0||(a[t]=e[t]);return a}(e,n);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(i=0;i<r.length;i++)t=r[i],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(a[t]=e[t])}return a}var l=i.createContext({}),p=function(e){var n=i.useContext(l),t=n;return e&&(t="function"==typeof e?e(n):o(o({},n),e)),t},m=function(e){var n=p(e.components);return i.createElement(l.Provider,{value:n},e.children)},c={inlineCode:"code",wrapper:function(e){var n=e.children;return i.createElement(i.Fragment,{},n)}},g=i.forwardRef((function(e,n){var t=e.components,a=e.mdxType,r=e.originalType,l=e.parentName,m=s(e,["components","mdxType","originalType","parentName"]),g=p(t),u=a,d=g["".concat(l,".").concat(u)]||g[u]||c[u]||r;return t?i.createElement(d,o(o({ref:n},m),{},{components:t})):i.createElement(d,o({ref:n},m))}));function u(e,n){var t=arguments,a=n&&n.mdxType;if("string"==typeof e||a){var r=t.length,o=new Array(r);o[0]=g;var s={};for(var l in n)hasOwnProperty.call(n,l)&&(s[l]=n[l]);s.originalType=e,s.mdxType="string"==typeof e?e:a,o[1]=s;for(var p=2;p<r;p++)o[p]=t[p];return i.createElement.apply(null,o)}return i.createElement.apply(null,t)}g.displayName="MDXCreateElement"},93397:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>c,frontMatter:()=>r,metadata:()=>s,toc:()=>p});var i=t(87462),a=(t(67294),t(3905));const r={},o="Smart Microscopy Workflows with Jupyter Notebooks",s={unversionedId:"ImSwitch/Advanced/Tutorials/Jupyter-Workflows",id:"ImSwitch/Advanced/Tutorials/Jupyter-Workflows",title:"Smart Microscopy Workflows with Jupyter Notebooks",description:"Jupyter notebooks provide an ideal environment for developing interactive microscopy workflows, combining live hardware control, real-time data analysis, and visualization in a single interface.",source:"@site/docs/05_ImSwitch/Advanced/04_Tutorials/Jupyter-Workflows.md",sourceDirName:"05_ImSwitch/Advanced/04_Tutorials",slug:"/ImSwitch/Advanced/Tutorials/Jupyter-Workflows",permalink:"/docs/ImSwitch/Advanced/Tutorials/Jupyter-Workflows",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Image Processing with ImSwitch",permalink:"/docs/ImSwitch/Advanced/Tutorials/Image-Processing"},next:{title:"UC2-ESP32 Getting Started Tutorial",permalink:"/docs/ImSwitch/Advanced/Tutorials/UC2-ESP-Getting-Started"}},l={},p=[{value:"Overview",id:"overview",level:2},{value:"Setup and Installation",id:"setup-and-installation",level:2},{value:"Jupyter Environment Setup",id:"jupyter-environment-setup",level:3},{value:"ImSwitch Integration",id:"imswitch-integration",level:3},{value:"ImSwitch Integration",id:"imswitch-integration-1",level:3},{value:"ImSwitchClient Library",id:"imswitchclient-library",level:4},{value:"Basic Connection Setup",id:"basic-connection-setup",level:4},{value:"Interactive Hardware Control Widgets",id:"interactive-hardware-control-widgets",level:4},{value:"Live Imaging Widget",id:"live-imaging-widget",level:4},{value:"Automated Workflows",id:"automated-workflows",level:4},{value:"Time-lapse Imaging",id:"time-lapse-imaging",level:4},{value:"Google Colab Integration",id:"google-colab-integration",level:3},{value:"Advanced Workflows",id:"advanced-workflows",level:3},{value:"Installation",id:"installation",level:2},{value:"Getting Started",id:"getting-started",level:2},{value:"Initializing the Client",id:"initializing-the-client",level:3},{value:"Example: Moving a Stage and Acquiring an Image",id:"example-moving-a-stage-and-acquiring-an-image",level:3},{value:"Laser Control Example",id:"laser-control-example",level:3},{value:"Recording an Image",id:"recording-an-image",level:3},{value:"Setting Live View",id:"setting-live-view",level:3},{value:"API Overview",id:"api-overview",level:2},{value:"Positioners Manager",id:"positioners-manager",level:3},{value:"Lasers Manager",id:"lasers-manager",level:3},{value:"Recording Manager",id:"recording-manager",level:3},{value:"View Manager",id:"view-manager",level:3},{value:"Contributing",id:"contributing",level:2},{value:"License",id:"license",level:2}],m={toc:p};function c(e){let{components:n,...t}=e;return(0,a.kt)("wrapper",(0,i.Z)({},m,t,{components:n,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"smart-microscopy-workflows-with-jupyter-notebooks"},"Smart Microscopy Workflows with Jupyter Notebooks"),(0,a.kt)("p",null,"Jupyter notebooks provide an ideal environment for developing interactive microscopy workflows, combining live hardware control, real-time data analysis, and visualization in a single interface."),(0,a.kt)("h2",{id:"overview"},"Overview"),(0,a.kt)("p",null,"ImSwitch + Jupyter enables:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Interactive Experiments"),": Real-time parameter adjustment"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Live Data Analysis"),": Process images as they're acquired"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Workflow Documentation"),": Combine code, results, and explanations"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Reproducible Research"),": Share complete experimental protocols"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Educational Tools"),": Interactive learning environments")),(0,a.kt)("h2",{id:"setup-and-installation"},"Setup and Installation"),(0,a.kt)("h3",{id:"jupyter-environment-setup"},"Jupyter Environment Setup"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"# Install Jupyter with ImSwitch integration\npip install jupyter jupyterlab ipywidgets\npip install matplotlib seaborn plotly\npip install scikit-image opencv-python napari\n\n# Enable Jupyter widgets\njupyter nbextension enable --py widgetsnbextension\njupyter labextension install @jupyter-widgets/jupyterlab-manager\n\n# For napari integration\npip install napari[all]\n")),(0,a.kt)("h3",{id:"imswitch-integration"},"ImSwitch Integration"),(0,a.kt)("h3",{id:"imswitch-integration-1"},"ImSwitch Integration"),(0,a.kt)("p",null,"ImSwitch provides a powerful REST API that can be accessed from Jupyter notebooks using the ",(0,a.kt)("inlineCode",{parentName:"p"},"imswitchclient")," library. This enables remote control of microscopy hardware and creates interactive experimental workflows."),(0,a.kt)("h4",{id:"imswitchclient-library"},"ImSwitchClient Library"),(0,a.kt)("p",null,"The ",(0,a.kt)("inlineCode",{parentName:"p"},"imswitchclient")," provides a Python wrapper for the ImSwitch REST API, enabling:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Remote Control"),": Interface with ImSwitch through REST API endpoints"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Comprehensive Access"),": Control positioners, lasers, detectors, and imaging settings"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Interactive Exploration"),": FastAPI Swagger UI at ",(0,a.kt)("inlineCode",{parentName:"li"},"http://localhost:8001/docs")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Modular Design"),": Separate managers for different hardware components")),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Installation:")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"# Install from PyPI\n!pip install imswitchclient\n\n# Or install latest development version\n!pip install git+https://github.com/openUC2/imswitchclient.git\n")),(0,a.kt)("h4",{id:"basic-connection-setup"},"Basic Connection Setup"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'from imswitchclient import ImSwitchClient\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom IPython.display import display, clear_output\nimport ipywidgets as widgets\n\n# Connect to ImSwitch instance\n# For local instance:\nclient = ImSwitchClient(host="localhost", port=8001)\n\n# For remote instance (e.g., Raspberry Pi):\n# client = ImSwitchClient(host="192.168.1.100", port=8001)\n\n# Check connection\nif client.is_connected():\n    print("\u2713 Connected to ImSwitch")\n    print(f"Available positioners: {client.positionersManager.getAllDeviceNames()}")\n    print(f"Available detectors: {client.detectorsManager.getAllDeviceNames()}")\nelse:\n    print("\u2717 Connection failed")\n')),(0,a.kt)("h4",{id:"interactive-hardware-control-widgets"},"Interactive Hardware Control Widgets"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'# Create interactive widgets for hardware control\ndef create_stage_control_widget():\n    """Create interactive stage control widget"""\n    \n    # Get available positioners\n    positioners = client.positionersManager.getAllDeviceNames()\n    if not positioners:\n        print("No positioners available")\n        return\n    \n    positioner_name = positioners[0]\n    \n    # Create widgets\n    x_slider = widgets.FloatSlider(min=-5000, max=5000, step=100, description=\'X Position:\')\n    y_slider = widgets.FloatSlider(min=-5000, max=5000, step=100, description=\'Y Position:\')\n    z_slider = widgets.FloatSlider(min=-1000, max=1000, step=10, description=\'Z Position:\')\n    \n    move_button = widgets.Button(description="Move Stage", button_style=\'success\')\n    home_button = widgets.Button(description="Home All", button_style=\'warning\')\n    \n    # Position display\n    position_output = widgets.Output()\n    \n    def move_stage(b):\n        """Move stage to widget positions"""\n        with position_output:\n            clear_output(wait=True)\n            try:\n                # Move to absolute positions\n                client.positionersManager.move(\n                    positioner_name, \n                    "X", \n                    x_slider.value, \n                    absolute=True\n                )\n                client.positionersManager.move(\n                    positioner_name, \n                    "Y", \n                    y_slider.value, \n                    absolute=True\n                )\n                client.positionersManager.move(\n                    positioner_name, \n                    "Z", \n                    z_slider.value, \n                    absolute=True\n                )\n                print(f"\u2713 Moved to X={x_slider.value}, Y={y_slider.value}, Z={z_slider.value}")\n            except Exception as e:\n                print(f"\u2717 Move failed: {e}")\n    \n    def home_stage(b):\n        """Home all stage axes"""\n        with position_output:\n            clear_output(wait=True)\n            try:\n                # Home all axes (implementation depends on hardware)\n                print("\ud83c\udfe0 Homing stage...")\n                # client.positionersManager.home(positioner_name)\n                print("\u2713 Homing complete")\n            except Exception as e:\n                print(f"\u2717 Homing failed: {e}")\n    \n    move_button.on_click(move_stage)\n    home_button.on_click(home_stage)\n    \n    # Layout widgets\n    controls = widgets.VBox([\n        widgets.HTML("<h3>Stage Control</h3>"),\n        x_slider, y_slider, z_slider,\n        widgets.HBox([move_button, home_button]),\n        position_output\n    ])\n    \n    return controls\n\n# Display stage control widget\nstage_widget = create_stage_control_widget()\ndisplay(stage_widget)\n')),(0,a.kt)("h4",{id:"live-imaging-widget"},"Live Imaging Widget"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'def create_live_imaging_widget():\n    """Create live imaging interface"""\n    \n    # Get available detectors\n    detectors = client.detectorsManager.getAllDeviceNames()\n    if not detectors:\n        print("No detectors available")\n        return\n    \n    detector_name = detectors[0]\n    \n    # Create widgets\n    exposure_slider = widgets.FloatSlider(\n        min=1, max=1000, value=100, step=10,\n        description=\'Exposure (ms):\'\n    )\n    \n    gain_slider = widgets.FloatSlider(\n        min=1, max=10, value=1, step=0.1,\n        description=\'Gain:\'\n    )\n    \n    capture_button = widgets.Button(description="Capture Image", button_style=\'primary\')\n    live_button = widgets.ToggleButton(description="Live View", button_style=\'info\')\n    \n    # Image display\n    image_output = widgets.Output()\n    \n    def capture_image(b):\n        """Capture single image"""\n        with image_output:\n            clear_output(wait=True)\n            try:\n                # Set camera parameters\n                client.detectorsManager.setParameter(detector_name, \'ExposureTime\', exposure_slider.value)\n                client.detectorsManager.setParameter(detector_name, \'Gain\', gain_slider.value)\n                \n                # Capture image\n                image = client.recordingManager.snapImage()\n                \n                # Display image\n                plt.figure(figsize=(8, 6))\n                plt.imshow(image, cmap=\'gray\')\n                plt.title(f\'Captured Image - Exposure: {exposure_slider.value}ms, Gain: {gain_slider.value}\')\n                plt.colorbar()\n                plt.show()\n                \n            except Exception as e:\n                print(f"\u2717 Capture failed: {e}")\n    \n    def toggle_live_view(change):\n        """Toggle live view"""\n        if change[\'new\']:  # Live view enabled\n            print("\ud83d\udd34 Live view starting...")\n            # Implementation for live view would go here\n        else:  # Live view disabled\n            print("\u23f9\ufe0f Live view stopped")\n    \n    capture_button.on_click(capture_image)\n    live_button.observe(toggle_live_view, names=\'value\')\n    \n    # Layout widgets\n    controls = widgets.VBox([\n        widgets.HTML("<h3>Live Imaging</h3>"),\n        exposure_slider, gain_slider,\n        widgets.HBox([capture_button, live_button]),\n        image_output\n    ])\n    \n    return controls\n\n# Display imaging widget\nimaging_widget = create_live_imaging_widget()\ndisplay(imaging_widget)\n')),(0,a.kt)("h4",{id:"automated-workflows"},"Automated Workflows"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'def z_stack_acquisition(start_z, end_z, step_z, exposure_time=100):\n    """Automated Z-stack acquisition"""\n    \n    print("\ud83d\udd2c Starting Z-stack acquisition...")\n    \n    # Calculate Z positions\n    z_positions = np.arange(start_z, end_z + step_z, step_z)\n    images = []\n    \n    try:\n        # Set camera parameters\n        detector_name = client.detectorsManager.getAllDeviceNames()[0]\n        positioner_name = client.positionersManager.getAllDeviceNames()[0]\n        \n        client.detectorsManager.setParameter(detector_name, \'ExposureTime\', exposure_time)\n        \n        # Progress bar\n        progress = widgets.IntProgress(\n            value=0, min=0, max=len(z_positions),\n            description=\'Z-stack:\'\n        )\n        display(progress)\n        \n        for i, z_pos in enumerate(z_positions):\n            # Move to Z position\n            client.positionersManager.move(positioner_name, "Z", z_pos, absolute=True)\n            \n            # Wait for settling\n            import time\n            time.sleep(0.5)\n            \n            # Capture image\n            image = client.recordingManager.snapImage()\n            images.append(image)\n            \n            # Update progress\n            progress.value = i + 1\n            progress.description = f\'Z-stack: {z_pos:.1f}\u03bcm\'\n        \n        print(f"\u2713 Z-stack complete: {len(images)} images acquired")\n        \n        # Display results\n        fig, axes = plt.subplots(1, min(5, len(images)), figsize=(15, 3))\n        if len(images) == 1:\n            axes = [axes]\n        \n        for i, ax in enumerate(axes):\n            if i < len(images):\n                ax.imshow(images[i], cmap=\'gray\')\n                ax.set_title(f\'Z={z_positions[i]:.1f}\u03bcm\')\n                ax.axis(\'off\')\n        \n        plt.tight_layout()\n        plt.show()\n        \n        return images, z_positions\n        \n    except Exception as e:\n        print(f"\u2717 Z-stack failed: {e}")\n        return None, None\n\n# Example usage\nimages, positions = z_stack_acquisition(start_z=-100, end_z=100, step_z=50)\n')),(0,a.kt)("h4",{id:"time-lapse-imaging"},"Time-lapse Imaging"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'def time_lapse_acquisition(duration_minutes=10, interval_seconds=30):\n    """Automated time-lapse acquisition"""\n    \n    print(f"\u23f1\ufe0f Starting time-lapse: {duration_minutes} min, every {interval_seconds}s")\n    \n    import time\n    \n    total_frames = int((duration_minutes * 60) / interval_seconds)\n    images = []\n    timestamps = []\n    \n    try:\n        detector_name = client.detectorsManager.getAllDeviceNames()[0]\n        \n        # Progress bar\n        progress = widgets.IntProgress(\n            value=0, min=0, max=total_frames,\n            description=\'Time-lapse:\'\n        )\n        display(progress)\n        \n        start_time = time.time()\n        \n        for frame in range(total_frames):\n            # Capture image\n            image = client.recordingManager.snapImage()\n            current_time = time.time() - start_time\n            \n            images.append(image)\n            timestamps.append(current_time)\n            \n            # Update progress\n            progress.value = frame + 1\n            progress.description = f\'Frame {frame+1}/{total_frames}\'\n            \n            # Wait for next interval\n            if frame < total_frames - 1:  # Don\'t wait after last frame\n                time.sleep(interval_seconds)\n        \n        print(f"\u2713 Time-lapse complete: {len(images)} frames acquired")\n        \n        # Display sample frames\n        sample_indices = np.linspace(0, len(images)-1, min(5, len(images)), dtype=int)\n        \n        fig, axes = plt.subplots(1, len(sample_indices), figsize=(15, 3))\n        if len(sample_indices) == 1:\n            axes = [axes]\n        \n        for i, idx in enumerate(sample_indices):\n            axes[i].imshow(images[idx], cmap=\'gray\')\n            axes[i].set_title(f\'t={timestamps[idx]/60:.1f}min\')\n            axes[i].axis(\'off\')\n        \n        plt.tight_layout()\n        plt.show()\n        \n        return images, timestamps\n        \n    except Exception as e:\n        print(f"\u2717 Time-lapse failed: {e}")\n        return None, None\n\n# Example usage\n# images, times = time_lapse_acquisition(duration_minutes=5, interval_seconds=10)\n')),(0,a.kt)("h3",{id:"google-colab-integration"},"Google Colab Integration"),(0,a.kt)("p",null,"The ImSwitchClient works seamlessly with Google Colab, enabling cloud-based microscopy control:"),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Try these examples:")),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://colab.research.google.com/drive/1W3Jcw4gFn0jtQXa3_2aCtJYJglMNGkXr?usp=sharing"},(0,a.kt)("img",{parentName:"a",src:"https://colab.research.google.com/assets/colab-badge.svg",alt:"Open In Colab"}))," - Basic ImSwitch Control"),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://colab.research.google.com/github/openUC2/imswitchclient/blob/main/examples/StageCalibration.ipynb"},(0,a.kt)("img",{parentName:"a",src:"https://colab.research.google.com/assets/colab-badge.svg",alt:"Open In Colab"}))," - Stage Calibration"),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Colab Setup:")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'# Install ImSwitchClient in Colab\n!pip install imswitchclient\n\n# Connect to remote ImSwitch instance\nfrom imswitchclient import ImSwitchClient\n\n# Replace with your microscope\'s IP address\nMICROSCOPE_IP = "192.168.1.100"  # Your Raspberry Pi IP\nclient = ImSwitchClient(host=MICROSCOPE_IP, port=8001)\n')),(0,a.kt)("h3",{id:"advanced-workflows"},"Advanced Workflows"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'# Multi-position imaging\ndef multi_position_imaging(positions, z_stack_params=None):\n    """Acquire images at multiple XY positions"""\n    \n    positioner_name = client.positionersManager.getAllDeviceNames()[0]\n    all_images = []\n    \n    for i, (x, y) in enumerate(positions):\n        print(f"\ud83d\udccd Position {i+1}/{len(positions)}: ({x}, {y})")\n        \n        # Move to position\n        client.positionersManager.move(positioner_name, "X", x, absolute=True)\n        client.positionersManager.move(positioner_name, "Y", y, absolute=True)\n        \n        # Optional Z-stack at each position\n        if z_stack_params:\n            images, _ = z_stack_acquisition(**z_stack_params)\n            all_images.append(images)\n        else:\n            image = client.recordingManager.snapImage()\n            all_images.append(image)\n    \n    return all_images\n\n# Define positions (in stage units)\npositions = [(0, 0), (1000, 0), (0, 1000), (1000, 1000)]\n\n# Acquire images\n# images = multi_position_imaging(positions)\n')),(0,a.kt)("p",null,"This comprehensive integration enables powerful, interactive microscopy workflows directly from Jupyter notebooks, whether running locally, on Google Colab, or other cloud platforms."),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Open Source"),": Inspired by OpenFlexure Client, freely available under the MIT license.")),(0,a.kt)("h2",{id:"installation"},"Installation"),(0,a.kt)("p",null,"You can install ",(0,a.kt)("inlineCode",{parentName:"p"},"ImSwitchClient")," via pip:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"pip install imswitchclient\n")),(0,a.kt)("h2",{id:"getting-started"},"Getting Started"),(0,a.kt)("h3",{id:"initializing-the-client"},"Initializing the Client"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'import imswitchclient.ImSwitchClient as imc\n\n# Initialize the client\nclient = imc.ImSwitchClient(host="0.0.0.0", isHttps=True, port=8001)\n')),(0,a.kt)("h3",{id:"example-moving-a-stage-and-acquiring-an-image"},"Example: Moving a Stage and Acquiring an Image"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'import numpy as np\nimport matplotlib.pyplot as plt\nimport time\n\n# Retrieve positioner names\npositioner_names = client.positionersManager.getAllDeviceNames()\npositioner_name = positioner_names[0]\n\n# Get current position\ncurrent_positions = client.positionersManager.getPositionerPositions()[positioner_name]\ninitial_position = (current_positions["X"], current_positions["Y"])\n\n# Turn on illumination\nlaser_name = client.lasersManager.getLaserNames()[0]\nclient.lasersManager.setLaserActive(laser_name, True)\nclient.lasersManager.setLaserValue(laser_name, 512)\n\n# Move the stage and capture an image\ndef capture_image_at_position(x, y):\n    client.positionersManager.movePositioner(positioner_name, "X", x, is_absolute=True, is_blocking=True)\n    client.positionersManager.movePositioner(positioner_name, "Y", y, is_absolute=True, is_blocking=True)\n    last_frame = client.recordingManager.snapNumpyToFastAPI()\n    plt.imshow(last_frame)\n    plt.show()\n\n# Example scanning\nfor ix in range(5):\n    for iy in range(5):\n        new_x = initial_position[0] + ix * 50\n        new_y = initial_position[1] + iy * 50\n        capture_image_at_position(new_x, new_y)\n\n# Return stage to initial position\nclient.positionersManager.movePositioner(positioner_name, "X", initial_position[0], is_absolute=True, is_blocking=True)\nclient.positionersManager.movePositioner(positioner_name, "Y", initial_position[1], is_absolute=True, is_blocking=True)\n')),(0,a.kt)("h3",{id:"laser-control-example"},"Laser Control Example"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"laser_name = client.lasersManager.getLaserNames()[0]\nclient.lasersManager.setLaserActive(laser_name, True)\nclient.lasersManager.setLaserValue(laser_name, 800)\n\n# Verify laser status\nprint(client.lasersManager.getLaserNames())\nclient.lasersManager.setLaserActive(laser_name, False)\n")),(0,a.kt)("h3",{id:"recording-an-image"},"Recording an Image"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"# Take a snapshot\nimage = client.recordingManager.snapNumpyToFastAPI()\nplt.imshow(image)\nplt.show()\n")),(0,a.kt)("h3",{id:"setting-live-view"},"Setting Live View"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"client.viewManager.setLiveViewActive(True)\nclient.viewManager.setLiveViewCrosshairVisible(True)\nclient.viewManager.setLiveViewGridVisible(False)\n")),(0,a.kt)("h2",{id:"api-overview"},"API Overview"),(0,a.kt)("p",null,"The ImSwitch API provides access to various components:"),(0,a.kt)("h3",{id:"positioners-manager"},"Positioners Manager"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"getAllDeviceNames()")," - Get all available positioners."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"getPositionerPositions()")," - Get current position."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"movePositioner(name, axis, value, is_absolute, is_blocking)")," - Move the stage."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"homeAxis(name, axis, is_blocking)")," - Home the positioner.")),(0,a.kt)("h3",{id:"lasers-manager"},"Lasers Manager"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"getLaserNames()")," - Get available lasers."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"setLaserActive(name, status)")," - Turn laser on/off."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"setLaserValue(name, value)")," - Set laser intensity.")),(0,a.kt)("h3",{id:"recording-manager"},"Recording Manager"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"snapNumpyToFastAPI()")," - Capture an image."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"startRecording()")," - Begin recording."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"stopRecording()")," - Stop recording.")),(0,a.kt)("h3",{id:"view-manager"},"View Manager"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"setLiveViewActive(status)")," - Enable live view."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"setLiveViewCrosshairVisible(status)")," - Show/hide crosshair."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"setLiveViewGridVisible(status)")," - Show/hide grid.")),(0,a.kt)("h2",{id:"contributing"},"Contributing"),(0,a.kt)("p",null,"Contributions are welcome! Visit the GitHub repository for details: ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/openUC2/imswitchclient"},"https://github.com/openUC2/imswitchclient")),(0,a.kt)("h2",{id:"license"},"License"),(0,a.kt)("p",null,"This project is licensed under the MIT License."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"")))}c.isMDXComponent=!0}}]);